{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise I will:\n",
    "- Do automatic word sense disambiguation (WSD) using the context around an ambigious word\n",
    "- Apply the semantic knowledge in lexicons and WordNet to this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "This requires that you have downloaded the following NLTK corpora/lexicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package senseval to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package senseval is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('senseval')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing relevant modules and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import senseval\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from collections import defaultdict,Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.wsd import lesk\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import urllib.request\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is for the evaluation of features as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_stump_eval(L1,L2):\n",
    "    '''Returns crossvalidated accuracy for a two class classificaion problem using a decision stump \n",
    "    based on a single feature. L1 are feature values for first class, L2 feature values for second class'''\n",
    "    labels = [0]*len(L1) + [1]*len(L2)\n",
    "    data = np.array(L1 + L2).reshape(-1, 1)\n",
    "    clf = DecisionTreeClassifier(max_depth=1)\n",
    "    return np.mean(cross_val_score(clf, data, labels, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the WSD task\n",
    "\n",
    "I will be using the Senseval corpus, which has sense-tagged data for a small set of word types. Here, I will only look at the ambiguity of the word *line*. Note that this corpus is arranged in a way that is **NOT** typical for NLTK corpora, and so I have provided some starter code that will allow you to iterate over each \"instance\", which provides a case of the word *line* in some context, as well as information about which sense it is in that context. You will need to inspect this data manually to figure out how to use it.\n",
    "\n",
    "Reorganize the dataset into two Python dictionaries, `test_set` and `dev_set`, where the keys of each dictionary are the senses, and the values are a list of instances where *line* has that sense. The `test_set` should contain the first 200 instances per sense, and `dev_set` should contain all other instances for that sense (Each sense does have more than 200 instances). Going forward, I have used `dev_set` exclusively for inspecting output, but I have reported numbers from `test_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set = defaultdict(list)\n",
    "test_set = defaultdict(list)\n",
    "\n",
    "for instance in senseval.instances('line.pos'):\n",
    "    \n",
    "    sense = instance.senses[0]\n",
    "    if sense in test_set and len(test_set[sense]) == 200:\n",
    "        dev_set[sense].append(instance)\n",
    "    else:\n",
    "        test_set[sense].append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert len(dev_set['product']) == 2017\n",
    "assert len(test_set['product']) == 200\n",
    "        \n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset mapping\n",
    "\n",
    "To carry out a few of the exercises in this exercise, I will first need to associate each sense in the Senseval dataset with a synset in WordNet. First, printing out all the synsets associated with the word *line* along with their gloss (Don't be surprised to find that there are a lot of them, many more than the senses in Senseval!), and creating a Python dictionary which maps each sense to the best corresponding WordNet synset. It might also be useful for you to look at examples of each sense in `dev_set` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('line.n.01')\n",
      "a formation of people or things one beside another\n",
      "Synset('line.n.02')\n",
      "a mark that is long relative to its width\n",
      "Synset('line.n.03')\n",
      "a formation of people or things one behind another\n",
      "Synset('line.n.04')\n",
      "a length (straight or curved) without breadth or thickness; the trace of a moving point\n",
      "Synset('line.n.05')\n",
      "text consisting of a row of words written across a page or computer screen\n",
      "Synset('line.n.06')\n",
      "a single frequency (or very narrow band) of radiation in a spectrum\n",
      "Synset('line.n.07')\n",
      "a fortified position (especially one marking the most forward position of troops)\n",
      "Synset('argumentation.n.02')\n",
      "a course of reasoning aimed at demonstrating a truth or falsehood; the methodical process of logical reasoning\n",
      "Synset('cable.n.02')\n",
      "a conductor for transmitting electrical or optical signals or electric power\n",
      "Synset('course.n.02')\n",
      "a connected series of events or actions or developments\n",
      "Synset('line.n.11')\n",
      "a spatial location defined by a real or imaginary unidimensional extent\n",
      "Synset('wrinkle.n.01')\n",
      "a slight depression in the smoothness of a surface\n",
      "Synset('pipeline.n.02')\n",
      "a pipe used to transport liquids or gases\n",
      "Synset('line.n.14')\n",
      "the road consisting of railroad track and roadbed\n",
      "Synset('telephone_line.n.02')\n",
      "a telephone connection\n",
      "Synset('line.n.16')\n",
      "acting in conformity\n",
      "Synset('lineage.n.01')\n",
      "the descendants of one individual\n",
      "Synset('line.n.18')\n",
      "something (as a cord or rope) that is long and thin and flexible\n",
      "Synset('occupation.n.01')\n",
      "the principal activity in your life that you do to earn money\n",
      "Synset('line.n.20')\n",
      "in games or sports; a mark indicating positions or bounds of the playing area\n",
      "Synset('channel.n.05')\n",
      "(often plural) a means of communication or access\n",
      "Synset('line.n.22')\n",
      "a particular kind of product or merchandise\n",
      "Synset('line.n.23')\n",
      "a commercial organization serving as a common carrier\n",
      "Synset('agate_line.n.01')\n",
      "space for one line of print (one column wide and 1/14 inch deep) used to measure advertising\n",
      "Synset('credit_line.n.01')\n",
      "the maximum credit that a customer is allowed\n",
      "Synset('tune.n.01')\n",
      "a succession of notes forming a distinctive sequence\n",
      "Synset('line.n.27')\n",
      "persuasive but insincere talk that is usually intended to deceive or impress\n",
      "Synset('note.n.02')\n",
      "a short personal letter\n",
      "Synset('line.n.29')\n",
      "a conceptual separation or distinction\n",
      "Synset('production_line.n.01')\n",
      "mechanical system in a factory whereby an article is conveyed through sites at which successive operations are performed on it\n",
      "Synset('line.v.01')\n",
      "be in line with; form a line along\n",
      "Synset('line.v.02')\n",
      "cover the interior of\n",
      "Synset('trace.v.02')\n",
      "make a mark or lines on a surface\n",
      "Synset('line.v.04')\n",
      "mark with lines\n",
      "Synset('line.v.05')\n",
      "fill plentifully\n",
      "Synset('line.v.06')\n",
      "reinforce with fabric\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('line'):\n",
    "    print(synset)\n",
    "    print(synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_lookup = {}\n",
    "\n",
    "synset_lookup['cord'] = wn.synset('line.n.18')\n",
    "synset_lookup['division'] = wn.synset('line.n.29')\n",
    "synset_lookup['formation'] = wn.synset('line.n.03')\n",
    "synset_lookup['product'] = wn.synset('line.n.22')\n",
    "synset_lookup['text'] = wn.synset('line.n.05')\n",
    "synset_lookup['phone'] = wn.synset('telephone_line.n.02')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesk\n",
    "\n",
    "Applying the Lesk algorithm for WSD and printing out the accuracy for the `test_set`. I also indicate the most common sense baseline for this test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "0.005\n",
      "most common sense\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for sense in test_set:\n",
    "    for instance in test_set[sense]:\n",
    "        total += 1\n",
    "        if lesk([pair[0].lower() for pair in instance.context], 'line', 'n') == synset_lookup[sense]:\n",
    "            correct += 1\n",
    "            \n",
    "print('result')           \n",
    "print(correct/total)\n",
    "print('most common sense')\n",
    "print(1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cord\n",
      "Synset('agate_line.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('occupation.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('line.n.20')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "division\n",
      "Synset('occupation.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('argumentation.n.02')\n",
      "Synset('production_line.n.01')\n",
      "Synset('line.n.14')\n",
      "Synset('line.n.20')\n",
      "Synset('production_line.n.01')\n",
      "Synset('production_line.n.01')\n",
      "formation\n",
      "Synset('agate_line.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('lineage.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('occupation.n.01')\n",
      "Synset('line.n.20')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('line.n.20')\n",
      "Synset('production_line.n.01')\n",
      "phone\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('line.n.20')\n",
      "Synset('occupation.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('argumentation.n.02')\n",
      "Synset('occupation.n.01')\n",
      "Synset('occupation.n.01')\n",
      "product\n",
      "Synset('agate_line.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('occupation.n.01')\n",
      "Synset('occupation.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "Synset('agate_line.n.01')\n",
      "text\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('occupation.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('wrinkle.n.01')\n",
      "Synset('production_line.n.01')\n",
      "Synset('agate_line.n.01')\n"
     ]
    }
   ],
   "source": [
    "for sense in dev_set:\n",
    "    print(sense)\n",
    "    for instance in dev_set[sense][:10]:\n",
    "        print(lesk([pair[0].lower() for pair in instance.context], 'line', 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussing the results from the LESK algorithm:\n",
    "\n",
    "The results are well below the most common sense baselines. This is because Lesk actually keeps choosing senses that aren't even among the senses included in the Senseval dataset. An easy way to improve things considerably would be to limit Lesk to the senses actually represented in the `test_set`. However, this won't solve the deep problem that the words in the context don't seem to be appearing in the glosses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-implementing the Lesk algorthm based on the flaws I saw above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "0.22833333333333333\n"
     ]
    }
   ],
   "source": [
    "def my_lesk(context_sentence,ambiguous_word):\n",
    "    '''does the lesk algorithm but limits the output to the synsets in synset_lookup'''\n",
    "    context = set(context_sentence)\n",
    "    synsets = wn.synsets(ambiguous_word)    \n",
    "    return max((len(context.intersection(ss.definition().split())), ss) for ss in synsets if ss in synset_lookup.values())[1]\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for sense in test_set:\n",
    "    for instance in test_set[sense]:\n",
    "        total += 1\n",
    "        if my_lesk([pair[0].lower() for pair in instance.context], 'line') == synset_lookup[sense]:\n",
    "            correct += 1\n",
    "            \n",
    "print(\"result\")           \n",
    "print(correct/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet distance\n",
    "\n",
    "Trying to do WSD by picking the synset that is closest (in WordNet) to the synsets of mostly non-ambigious context words.\n",
    "\n",
    "\n",
    "The biggest challenge in this problem is identifying \"mostly\" non-ambiguous words. I could exclude any word type that has any polysemy (i.e. associated with more than one synset), but that seems too extreme. Instead, I am going to consider a word mostly non-ambiguous if it appears as one particular sense 75% of the time, based on the corpus counts provided in WordNet. I have written  a general function, `get_dominant_sense`, which takes a word and a POS (a single letter, same as the input to the WordNet lemmatizer), and returns the dominant (75% of instances) synset if it exists, or `None` if it doesn't. The POS will be useful because, in order to do this properly, I will have to correctly lemmatize the word, so as to match it with the lemmas of each of its synset, so you can get the right count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_sense_ratio = 0.75\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_dominant_sense(word,pos):\n",
    "    if pos.startswith(\"N\"):\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    elif pos.startswith(\"V\"):\n",
    "        lemma = lemmatizer.lemmatize(word,'v')\n",
    "    else:\n",
    "        lemma = word\n",
    "    syn_counts = []\n",
    "    total = 0\n",
    "    for synset in wn.synsets(word):\n",
    "        for wn_lemma in synset.lemmas():\n",
    "            if lemma == wn_lemma.name():\n",
    "                lemma_count = wn_lemma.count()\n",
    "                total += lemma_count\n",
    "                syn_counts.append([lemma_count,synset])\n",
    "    syn_counts.sort()\n",
    "    if total > 0 and syn_counts[-1][0]/total >= dominant_sense_ratio:\n",
    "        return syn_counts[-1][1]\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert str(get_dominant_sense(\"word\",\"n\")) == \"Synset('word.n.01')\"\n",
    "assert get_dominant_sense(\"fun\",\"n\") is None\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2\n",
    "\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Now write a `get_wordnet_context_similarities` function which builds a list of synsets associated with nouns in the context for an given instance (using the `get_dominant_sense` function from **3.1**) and then calculates the average Wu-Palmer similarity from each of those synsets to the synsets associated with each of the possible senses of line ( and the `synset lookup` from **1**). If you correctly implement `get_wordnet_context_similarities`, the code provided below will calculate the WSD accuracy on the `test_set` (don't be surprised if it is fairly slow, and the result isn't that good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18666666666666668\n"
     ]
    }
   ],
   "source": [
    "def get_wordnet_context_similarities(instance,synset_lookup):\n",
    "    '''returns a dictionary of average Wu-Palmer similarities between the synsets in synset lookup \n",
    "    to the dominent senses of the nouns in the context of the instance'''\n",
    "    context_similarity_dict = defaultdict(int)\n",
    "    # your code here\n",
    "    total = 0\n",
    "    for word_pos_pair in instance.context:\n",
    "        if len(word_pos_pair) == 2 and word_pos_pair[1].startswith(\"N\"):\n",
    "            token,pos = word_pos_pair\n",
    "            context_synset = get_dominant_sense(token,pos)\n",
    "            if not context_synset is None:\n",
    "                for word_sense,word_synset in synset_lookup.items():\n",
    "                    similarity = synset_lookup[word_sense].wup_similarity(context_synset)\n",
    "                    if not similarity is None:\n",
    "                        total +=1\n",
    "                        context_similarity_dict[word_sense] += similarity\n",
    "    for sense in context_similarity_dict:\n",
    "        context_similarity_dict[sense] /= total\n",
    "    # your code here\n",
    "    return context_similarity_dict\n",
    "\n",
    "def get_closest_sense(instance,synset_lookup):\n",
    "    '''gets the sense of the senses in synset_look that is on average most similar to\n",
    "    the words in the context of instance'''\n",
    "    context_similarities = get_wordnet_context_similarities(instance,synset_lookup)\n",
    "    if len(context_similarities) == 0:\n",
    "        return None\n",
    "    \n",
    "    max_value = max(context_similarities.values())\n",
    "    for sense,value in context_similarities.items():\n",
    "        if value == max_value:\n",
    "            return sense \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for sense in test_set:\n",
    "    for instance in test_set[sense]:\n",
    "        total += 1\n",
    "        if get_closest_sense(instance,synset_lookup) == sense:\n",
    "            correct += 1\n",
    "            \n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Hand-crafted lexicon\n",
    "\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Pick a sense of \"line\", and examine some of the contexts for instances of that sense in the `dev_set`. Based on this, build a small lexicon of words (at least 5) that consistently appear in contexts for that sense, and, using the provided `decision_stump_eval` function, show that this small lexicon works as a useful feature for distinguishing that sense from all other senses (you just need to pass `decision_stump_eval` two lists of numbers corresponding to the counts for the instances of the two different senses). A simple function for counting the number of times a word from a lexicon appears in a semeval instance is provided (note that there is an error in the semeval annotation which it handles!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cord\n",
      "0.8174999999999999\n",
      "division\n",
      "0.8175000000000001\n",
      "formation\n",
      "0.8175000000000001\n",
      "product\n",
      "0.8125\n",
      "text\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences_in_context(instance,lexicon):\n",
    "    '''count how often the words in lexicon appear in the context of the provided semeval instance'''\n",
    "    count = 0\n",
    "    for pair in instance.context:\n",
    "        if len(pair) == 2:\n",
    "            word,pos = pair\n",
    "            if word in phone_words:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "#your code here\n",
    "phone_words = set([\"telephone\",\"phone\",\"dial\",'telecommunications',\"block\"])\n",
    "\n",
    "def count_all(instances,lexicon):\n",
    "    return [count_occurrences_in_context(instance, lexicon) for instance in instances]\n",
    "\n",
    "counts_for_phone_sense = count_all(test_set[\"phone\"],phone_words)\n",
    "\n",
    "for other_sense in test_set:\n",
    "    if other_sense != \"phone\":\n",
    "        counts_for_other_sense = count_all(test_set[other_sense],phone_words)\n",
    "        print(other_sense)\n",
    "        print(decision_stump_eval(counts_for_other_sense,counts_for_phone_sense))\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Concreteness\n",
    "\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "One typical distinction between senses of a word is that some senses are more concrete (involving the physical world) whereas others are more abstract. A list of words with human-assigned concreteness ratings can be found on the webpage [here](https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt). The code below will extract it into a Python dictionary for your use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39954\n"
     ]
    }
   ],
   "source": [
    "#provided code\n",
    "concreteness_dict = {}\n",
    "\n",
    "for line in urllib.request.urlopen(\"https://raw.githubusercontent.com/ArtsEngine/concreteness/master/Concreteness_ratings_Brysbaert_et_al_BRM.txt\").read().decode(\"utf-8\").split(\"\\n\"):\n",
    "    if line.startswith(\"Word\") or not line.strip():\n",
    "        continue\n",
    "    line = line.split(\"\\t\")\n",
    "    concreteness_dict[line[0]] = float(line[2])\n",
    "    \n",
    "print(len(concreteness_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose two senses of *line* that you think should be distinguishable based on concreteness. Calculate an average concreteness for the contexts of each instance of each sense, and print the results of using `decision_stump_eval` on those concreteness values (separated by sense) as well the total average context concreteness for each sense. Together, these should show that your hypothesis was correct. If it wasn't, try a different pair of senses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cord concreteness:\n",
      "2.7302934692625183\n",
      "division concreteness:\n",
      "2.4681902854215854\n",
      "decision stump evaluation:\n",
      "0.7575000000000001\n"
     ]
    }
   ],
   "source": [
    "def calculate_concreteness(instance,concreteness_dict):\n",
    "    '''calcualte average concreteness based on the words of the context of instance and the\n",
    "    provided concreteness_diction for each word'''\n",
    "    concreteness = 0\n",
    "    total_words = 0\n",
    "    for pair in instance.context:\n",
    "        if len(pair) == 2:\n",
    "            word = pair[0].lower() \n",
    "            if word in concreteness_dict:\n",
    "                concreteness += concreteness_dict[word]\n",
    "                total_words += 1\n",
    "    return concreteness/total_words\n",
    "\n",
    "def get_concretenesses_for_instances(instances,concreteness_dict):\n",
    "    L = []\n",
    "    for instance in instances:\n",
    "        L.append(calculate_concreteness(instance,concreteness_dict))\n",
    "    return L\n",
    "\n",
    "L1 = get_concretenesses_for_instances(test_set[\"cord\"],concreteness_dict)\n",
    "L2 = get_concretenesses_for_instances(test_set[\"division\"],concreteness_dict)\n",
    "print(\"cord concreteness:\")\n",
    "print(np.mean(L1))\n",
    "print(\"division concreteness:\")\n",
    "print(np.mean(L2))\n",
    "print(\"decision stump evaluation:\")\n",
    "print(decision_stump_eval(L1,L2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Hypernyms\n",
    "\n",
    "#### 6.1\n",
    "\n",
    "rubric={accuracy:2, efficiency:1}\n",
    "\n",
    "In this exercise you'll be looking at the WordNet hypernyms of words appearing in the context as potential features for doing WSD. First, you need to write a recursive function `get_all_hypernyms` which collects the names (e.g. `synset.name()`) of a provided WordNet synset and all of its hypernyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_hypernyms(synset):\n",
    "    '''return a list of all the WordNet hypernyms of a provided synset'''\n",
    "    # your code here\n",
    "    hypernyms = [synset.name()]\n",
    "    for hypernym in synset.hypernyms():\n",
    "        if not hypernym is None:\n",
    "            hypernyms.extend(get_all_hypernyms(hypernym))\n",
    "    return hypernyms\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert get_all_hypernyms(wn.synsets(\"cat\")[0]) == ['cat.n.01', 'feline.n.01', 'carnivore.n.01', 'placental.n.01', 'mammal.n.01', 'vertebrate.n.01', 'chordate.n.01', 'animal.n.01', 'organism.n.01', 'living_thing.n.01', 'whole.n.02', 'object.n.01', 'physical_entity.n.01', 'entity.n.01']\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 (Optional)\n",
    "\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Next, use the `get_dominant_sense` function from **2.1** and the `get_all_hypernyms` function from **6.1** to create, for each instance in your dataset, a Counter of all the hypernyms for all  words (which have a single dominant sense) in the context. You should use this to create a Python dictionary analogous to `test_set`, except the values are a list of Counters with the counts of context synsets (names). At the same time, you should maintain a separate Counter, `total_counter` which counts the appearance of these synsets across the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counter = Counter()\n",
    "\n",
    "#your code here\n",
    "\n",
    "def get_synsets_for_instance(instance):\n",
    "    '''Get a counter of all the hypernym synset in instance'''\n",
    "    counts = Counter()\n",
    "    for word_pos_pair in instance.context:\n",
    "        if len(word_pos_pair) == 2:\n",
    "            token,pos = word_pos_pair\n",
    "            synset = get_dominant_sense(token,pos)\n",
    "            if not synset is None:\n",
    "                counts.update(get_all_hypernyms(synset))\n",
    "    return counts\n",
    "\n",
    "instance_counts_dict = defaultdict(list)\n",
    "for sense in test_set:\n",
    "    for instance in test_set[sense]:\n",
    "        instance_counts = get_synsets_for_instance(instance)\n",
    "        instance_counts_dict[sense].append(instance_counts)\n",
    "        total_counter.update(instance_counts)\n",
    "\n",
    "#your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "assert len(total_counter) == 3971\n",
    "assert total_counter.most_common(1)[0] == ('entity.n.01',6615)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 (Optional)\n",
    "\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Print out the 100 most common synsets across the entire dataset. Among this top 100, pick a synset that you think will distinguish two of the senses. Briefly justify your choice in the markdown box below. Then test whether it indeed does. You'll want to normalize your counts of the hypernyms in some way, e.g. using the total number of hypernyms for that instance. You should show (i) whether the synset from the context does distinguish the two contexts using `decision_stump_eval` and (ii) whether the directionality is what you would expect. It is okay if your hypothesis is wrong, provided your original idea was sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('entity.n.01', 6615), ('physical_entity.n.01', 4032), ('abstraction.n.06', 2581), ('object.n.01', 2509), ('whole.n.02', 2310), ('artifact.n.01', 1139), ('living_thing.n.01', 1138), ('organism.n.01', 1135), ('causal_agent.n.01', 1085), ('in.r.01', 1047), ('person.n.01', 1044), ('psychological_feature.n.01', 707), ('instrumentality.n.03', 602), ('measure.n.02', 571), ('group.n.01', 551), ('event.n.01', 531), ('state.v.01', 461), ('express.v.02', 461), ('act.n.02', 377), ('along.r.01', 374), ('social_group.n.01', 359), ('attribute.n.02', 319), ('equally.r.01', 302), ('fundamental_quantity.n.01', 290), ('time_period.n.01', 280), ('organization.n.01', 277), ('matter.n.03', 271), ('device.n.01', 262), ('communication.n.02', 245), ('by.r.01', 244), ('merely.r.01', 225), ('structure.n.01', 220), ('new.a.01', 213), ('one.s.01', 201), ('relation.n.01', 188), ('definite_quantity.n.01', 175), ('cognition.n.01', 171), ('act.v.01', 161), ('machine.n.01', 161), ('conveyance.n.03', 150), ('activity.n.01', 146), ('vehicle.n.01', 146), ('two.s.01', 138), ('substance.n.07', 138), ('unit_of_measurement.n.01', 135), ('year.n.01', 134), ('location.n.01', 133), ('thing.n.12', 123), ('worker.n.01', 118), ('some.a.01', 118), ('state.n.02', 117), ('quality.n.01', 110), ('there.r.01', 109), ('part.n.01', 106), ('travel.v.01', 106), ('computer.n.01', 106), ('message.n.02', 106), ('not.r.01', 103), ('transfer.v.05', 102), ('group_action.n.01', 102), ('up.r.01', 101), ('leader.n.01', 99), ('content.n.05', 99), ('other.a.01', 99), ('capitalist.n.02', 99), ('user.n.01', 99), ('interact.v.01', 97), ('container.n.01', 94), ('food.n.01', 91), ('consumer.n.01', 91), ('adult.n.01', 90), ('think.v.03', 90), ('three.s.01', 89), ('substance.n.01', 87), ('region.n.03', 87), ('use.v.01', 84), ('communicate.v.02', 81), ('unit.n.03', 77), ('possession.n.02', 77), ('body_part.n.01', 76), ('part.n.03', 76), ('move.v.02', 74), ('skilled_worker.n.01', 74), ('businessperson.n.01', 74), ('craft.n.02', 73), ('animal.n.01', 73), ('building.n.01', 72), ('besides.r.02', 72), ('wheeled_vehicle.n.01', 71), ('all.a.01', 71), ('action.n.01', 69), ('vessel.n.02', 69), ('subsequently.r.01', 69), ('commodity.n.01', 69), ('covering.n.02', 68), ('customer.n.01', 68), ('change.v.01', 66), ('include.v.01', 66), ('motor_vehicle.n.01', 66), ('self-propelled_vehicle.n.01', 66)]\n"
     ]
    }
   ],
   "source": [
    "print(total_counter.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I choose the object synset to distinguish the \"cord\" and \"division\" senses of *line*. My expectation is that use of line in the sense of \"cord\" will often involve physical objects, where as \"division\" is more abstract and won't involve physical objects as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval\n",
      "Normalized count for  cord\n",
      "0.03949330292738305\n",
      "Normalized count for  division\n",
      "0.027364713915378668\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "def get_normalized_synset_counts(list_of_counts, synset):\n",
    "    output = []\n",
    "    for counts in list_of_counts:\n",
    "        total = sum(counts.values())\n",
    "        if total == 0 or synset not in counts:\n",
    "            output.append(0)\n",
    "        else:\n",
    "            output.append(counts[synset]/total)\n",
    "    return output\n",
    "\n",
    "def check_if_synset_distinguishes_sense(synset,sense1,sense2,verbose=True):\n",
    "    sense1_counts = get_normalized_synset_counts(instance_counts_dict[sense1],synset)\n",
    "    if verbose:\n",
    "        print(\"Normalized count for \",  sense1)\n",
    "        print(np.mean(sense1_counts))\n",
    "    sense2_counts = get_normalized_synset_counts(instance_counts_dict[sense2],synset)\n",
    "    if verbose:\n",
    "        print(\"Normalized count for \",  sense2)\n",
    "        print(np.mean(sense2_counts))\n",
    "    return decision_stump_eval(sense1_counts,sense2_counts)\n",
    "print(\"Eval\")\n",
    "print(check_if_synset_distinguishes_sense(\"object.n.01\",\"cord\",\"division\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
