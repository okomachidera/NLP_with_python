{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLX 565 Lab Assignment 3: Amazon reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will\n",
    "- Carefully evaluate approaches to polarity classification using large datasets\n",
    "- Do fine-grained sentiment analysis with SVM Ranking\n",
    "- Compare automatically-generated scores with gold-standard scores for profiling Amazon reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to access relevant modules (you can add to this as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Submission\n",
    "\n",
    "rubric={mechanics:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the marks for tidy submission:\n",
    "\n",
    "- Submit the assignment by filling in this jupyter notebook with your answers embedded\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions)\n",
    "- You should download the Amazon product review corpora but do not include them with your submission. Modify the path below. You also should not unzip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_review_dir = \"/Users/chidera/Desktop/COLX_565/amazon_reviews/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Evaluation of polarity classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll be building SVM models with collections of amazon reviews. Go to [this site](http://jmcauley.ucsd.edu/data/amazon/) and download the 5-core review sets for the following product types: \"Video Games\", \"Beauty\", \"Cell Phones and Accessories\", and \"Musical Instruments\". You will not actually present any results involving \"Musical Instruments\" in this lab, since the dataset is too small (a mere ten thousand reviews!), but you should use Musical Instruments for testing. For everything else in this lab, you should run things with all three datasets to see if your results are consistent (for the most part, they should be, though with small variations).\n",
    "\n",
    "Each review in the corpus consists of the following information."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "  \"reviewerID\": \"A2SUAM1J3GNN3B\",\n",
    "  \"asin\": \"0000013714\",\n",
    "  \"reviewerName\": \"J. McDonald\",\n",
    "  \"helpful\": [2, 3],\n",
    "  \"reviewText\": \"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\",\n",
    "  \"overall\": 5.0,\n",
    "  \"summary\": \"Heavenly Highway Hymns\",\n",
    "  \"unixReviewTime\": 1252800000,\n",
    "  \"reviewTime\": \"09 13, 2009\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will make use of the following aspects of the review: \"reviewText\" (the content of the review), \"summary\" (the title), \"reviewerID\" (a unique identifier indicating who wrote it, \"asin\" (the serial number of the product), and, most importantly, \"overall\", which gives a star rating to the review on a 1-5 scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1\n",
    "rubric={accuracy:1,efficiency:1}\n",
    "\n",
    "Below is some code which loads in one of the data files and creates a test set by randomly selecting reviews. We could take everything else as our training set, but we'd like to evaluate our classifier in the context where it cannot take advantage of the biases associated with particular reviewers and products. Your first task is finish this function so it creates a training set (`train_set`) which consists of all the reviews which do not involve *either* a reviewer or a product that appears in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amazon_reviews_no_dups(corpus_path,test_size=2000,seed=42):\n",
    "    '''loads a gzipped amazon review corpus, sampling a test set of 2000 reviews, with the rest becoming\n",
    "    training provided that they are not reviews of the same product or written by the same reviewers\n",
    "    as training data'''\n",
    "    g = gzip.open(corpus_path, 'r')\n",
    "\n",
    "    all_reviews = [eval(line) for line in g]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_reviews)\n",
    "    test_set = random.sample(all_reviews, test_size)\n",
    "\n",
    "    test_lookup = set()\n",
    "    train_set = list()\n",
    "    for review in test_set:\n",
    "        test_lookup.add(review['reviewerID'])\n",
    "        test_lookup.add(review['asin'])\n",
    "        \n",
    "    for review in all_reviews:\n",
    "        if review not in test_set:\n",
    "            if review['reviewerID'] in test_lookup or review['asin'] in test_lookup:\n",
    "                continue\n",
    "            else:\n",
    "                train_set.append(review)\n",
    "\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Musical_Instruments_5.json.gz\",test_size=200)\n",
    "assert len(train_set) == 6100\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2\n",
    "rubric={accuracy:1,quality:1}\n",
    "\n",
    "Next, we need to prepare the data for sklearn. The provided `prepare_for_classification` uses a CountVectorizer for this purpose. You need to write the `prepare_for_vectorizer` function which should convert the review format into a list of strings (the texts), and the list of *binary* classifications (positive and negative, less than 3 is negative, greater than 3 is positive). You should include both the summary (title) and the body of the review together as the text, and you should exclude reviews which have a rating of 3 as being neither positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "def prepare_for_vectorizer(data):\n",
    "    '''\n",
    "    input: Takes a list of reviews \n",
    "    output: A list of strings and list of classes \n",
    "    '''\n",
    "    texts = list()\n",
    "    classes = list()\n",
    "    for review in data:\n",
    "        if review['overall'] < 3:\n",
    "            classes.append('negative')\n",
    "            texts.append(review['summary'] + ' ' + review['reviewText'] )\n",
    "        elif review['overall'] > 3:\n",
    "            classes.append('positive')\n",
    "            texts.append(review['summary'] + ' ' + review['reviewText'])\n",
    "            \n",
    "    \n",
    "    return texts, classes\n",
    "\n",
    "def prepare_for_classification(train,test,max_n=2):\n",
    "    '''convert lists of reviews train and test to spare feature matrices X_train and X_test,\n",
    "    and lists of binary polarity classifications train_class and test_class'''\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,max_n),min_df=2)\n",
    "    train_texts, train_class = prepare_for_vectorizer(train)\n",
    "    test_texts, test_class = prepare_for_vectorizer(test)\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    return X_train,train_class, X_test,test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "music_train, train_class, music_test, test_class = prepare_for_classification(train_set,test_set)\n",
    "assert music_train.shape[0] == 5641\n",
    "assert music_train.shape[1] == 57515\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "Now, using the three large datasets and the functions above (note the `max_n` keyword argument for `prepare_for_classification`), investigate which choice of $n$ gives you the best results for linear SVM $n$-gram models (check n=1,2,3). Since these datasets are imbalanced, you should evaluate with macro-averaged f-score instead of accuracy. You should also print the shape of your training set matrix for each test that you do (they are extremely big!). This will take a while with the main datasets, again you should test it with the smaller one first...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty_train, beauty_test = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Beauty_5.json.gz\",test_size=2000)\n",
    "cell_phone_train, cell_phone_test = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Cell_Phones_and_Accessories_5.json.gz\",test_size=2000)\n",
    "video_train, video_test = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Video_Games_5.json.gz\",test_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = [beauty_train, cell_phone_train, video_train]\n",
    "all_test = [beauty_test, cell_phone_test, video_test]\n",
    "data = ['beauty', 'cell_phone', 'video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beauty  F_score for n_gram 1,2,3\n",
      "[0.8387896448566143, 0.9129808885579549, 0.9158339741790055]\n",
      "*************\n",
      "cell_phone  F_score for n_gram 1,2,3\n",
      "[0.8515663726867151, 0.8842865497976082, 0.8935686557637776]\n",
      "*************\n",
      "video  F_score for n_gram 1,2,3\n",
      "[0.8530208389424372, 0.8953999859847233, 0.8874218575726746]\n",
      "*************\n"
     ]
    }
   ],
   "source": [
    "all_train = [beauty_train, cell_phone_train, video_train]\n",
    "all_test = [beauty_test, cell_phone_test, video_test]\n",
    "n_gram = [1,2,3]\n",
    "for i in range(len(all_train)):\n",
    "    f1_list = list()\n",
    "    for max_n in n_gram:\n",
    "        X_train, train_class, X_test, test_class = prepare_for_classification(all_train[i], all_test[i], max_n)\n",
    "        \n",
    "        clf = LinearSVC()\n",
    "        clf.fit(X_train, train_class)\n",
    "        prediction = clf.predict(X_test)\n",
    "        f1 = f1_score(test_class, prediction, average='macro')\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "    print(data[i], ' F_score for n_gram 1, 2, 3')     \n",
    "    print(f1_list)\n",
    "    print(\"*************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4\n",
    "rubric={accuracy:2,quality:1,viz:1}\n",
    "\n",
    "Having found a reasonable $n$ (if things are close, prefer the lower $n$), investigate the effect of the size of the training data on your classification preformance. You will create a line graph containing the results for all three corpora. Your X axis should be logrithmic, and you should check the range from 10 to 100000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best n_gram for each data set for the results above \n",
    "best_n_gram = [3, 3, 2]\n",
    "\n",
    "## Slicing range for the visualization\n",
    "slicing_range = [10**exp for exp in range(2, 6)]\n",
    "\n",
    "data = ['beauty', 'cell_phone', 'video']\n",
    "\n",
    "f1_list = defaultdict(list)\n",
    "for i in range(len(all_train)):\n",
    "    X_train, train_class, X_test, test_class = prepare_for_classification(all_train[i], all_test[i], best_n_gram[i])\n",
    "    for j in slicing_range:\n",
    "        clf = LinearSVC()\n",
    "        clf.fit(X_train[:j], train_class[:j])\n",
    "        prediction = clf.predict(X_test)\n",
    "        f1 = f1_score(test_class, prediction, average='macro')\n",
    "        f1_list[data[i]].append((j, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'beauty': [(100, 0.4748692242268235),\n",
       "              (1000, 0.7269006092091074),\n",
       "              (10000, 0.8589860171655207),\n",
       "              (100000, 0.9215401454211067)],\n",
       "             'cell_phone': [(100, 0.6458221089110527),\n",
       "              (1000, 0.7593325407106395),\n",
       "              (10000, 0.8593083921868041),\n",
       "              (100000, 0.8842865497976082)],\n",
       "             'video': [(100, 0.4728150066795484),\n",
       "              (1000, 0.6952593469647981),\n",
       "              (10000, 0.8409244642464669),\n",
       "              (100000, 0.894687012211224)]})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig= plt.figure(figsize=(10,10))\n",
    "\n",
    "axes= fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "beauty_X = list()\n",
    "beauty_Y = list()\n",
    "cell_phone_X = list()\n",
    "cell_phone_Y = list()\n",
    "video_X = list()\n",
    "video_Y = list()\n",
    "print(len(f1_list['beauty']))\n",
    "for val in f1_list['beauty']:\n",
    "    beauty_X.append(val[0])\n",
    "    beauty_Y.append(val[1])\n",
    "    \n",
    "for val in f1_list['cell_phone']:\n",
    "    cell_phone_X.append(val[0])\n",
    "    cell_phone_Y.append(val[1])\n",
    "    \n",
    "for val in f1_list['video']:\n",
    "    video_X.append(val[0])\n",
    "    video_Y.append(val[1])\n",
    "    \n",
    "axes.plot(beauty_X, beauty_Y)\n",
    "axes.plot(cell_phone_X, cell_phone_Y)\n",
    "axes.plot(video_X, video_Y)\n",
    "axes.legend(['beauty', 'cell_phone', 'video'], loc='lower right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: SVM Ranking\n",
    "\n",
    "In this exercise, you will compare SVM regression to SVM ranking for predicting fine-grained opinion ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1\n",
    "rubric={accuracy:2,quality:1}\n",
    "\n",
    "First, do the regression version. Relative to what you did in exercise 1, there are three changes\n",
    "\n",
    "- adapt the `prepare_for_vectorizer` function to `prepare_for_vectorizer_regression` function which no longer binarizes the data\n",
    "- change the SVC (support vector classifier) to a SVR (support vector regressor)\n",
    "- evalute the predicted ranks against the original ranks using Kendall's Tau, not f-score\n",
    "\n",
    "As usual, run it for all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare for vectorizor regression\n",
    "#prepare for regression\n",
    "def prepare_for_vectorizer_regression(data):\n",
    "    '''\n",
    "    input: Takes a list of reviews \n",
    "    output: A list of strings and list of classes \n",
    "    '''\n",
    "    texts = list()\n",
    "    classes = list()\n",
    "    for review in data:\n",
    "        classes.append(review['overall'])\n",
    "        texts.append(review['summary'] + ' ' + review['reviewText'] )\n",
    "    \n",
    "    return texts, classes\n",
    "\n",
    "def prepare_for_regression(train,test,max_n=2):\n",
    "    '''convert lists of reviews train and test to spare feature matrices X_train and X_test,\n",
    "    and lists of binary polarity classifications train_class and test_class'''\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,max_n),min_df=2)\n",
    "    train_texts, train_class = prepare_for_vectorizer_regression(train)\n",
    "    test_texts, test_class = prepare_for_vectorizer_regression(test)\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    return X_train,train_class, X_test,test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'beauty': [(0.5259545905347947, 2.5851055387209322e-22)],\n",
       "             'cell_phone': [(0.4720111000380144, 1.5078874980399432e-18)],\n",
       "             'video': [(0.35204247246862014, 1.0772592899361658e-10)]})"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = defaultdict(list)\n",
    "for i in range(len(all_train)):\n",
    "    X_train, train_class, X_test, test_class = prepare_for_regression(all_train[i], all_test[i], best_n_gram[i])\n",
    "        \n",
    "    clf = LinearSVR()\n",
    "    clf.fit(X_train, train_class)\n",
    "    prediction = clf.predict(X_test)\n",
    "    tau, p_value = kendalltau(test_class, prediction)\n",
    "    result[data[i]].append((tau, p_value))\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2\n",
    "rubric={accuracy:3,efficiency:1}\n",
    "\n",
    "Now, you will implement SVMrank using LinearSVC. The main part is to write a function `convert to pairwise` which converts the normal output of `prepare_for_vectorizer_regression` and turns it into a (pairwise) classification task using the following logic:\n",
    "\n",
    "- for each original datapoint (feature vector), randomly select one other datapoint that has a different rating (you should keep trying until you get one, don't discard data!)\n",
    "- create a feature vector which is the difference between the two feature vectors\n",
    "- create a label which should be 1 if the rating of the first datapoint is larger than the second, or 0 if the second rating is larger\n",
    "\n",
    "You should return a new feature matrx and the corresponding list of labels. Note that you MUST preserve the sparsity of the feature matrix, these matrices are far too big to be densified.\n",
    "\n",
    "This will take a while for the 100k datapoints you have in each corpus, and so you should have a counter that shows your progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pairwise(data,ratings):\n",
    "    '''covert a normal collection of data with ordinal ratings into a pairwise classification task\n",
    "    by randomly choosing one comparison datapoint with a different rating and taking the direction of\n",
    "    the difference as the class of the new datapoint'''\n",
    "    # your code here\n",
    "    count = 0\n",
    "    pairwise_class = list()\n",
    "    pairwise_data = list()\n",
    "    num_of_examples = data.shape[0]\n",
    "    for i, row in enumerate(data):\n",
    "        count += 1\n",
    "        current_row = data[i]\n",
    "        current_class = ratings[i]\n",
    "        next_index = np.random.randint(0, num_of_examples)\n",
    "        while ratings[next_index] == current_class:\n",
    "            \n",
    "            next_index = np.random.randint(0, num_of_examples)\n",
    "        \n",
    "        next_example = data[next_index]\n",
    "        difference = current_row - next_example\n",
    "\n",
    "        if current_class > ratings[next_index]:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        pairwise_data.append(difference)\n",
    "        pairwise_class.append(label)\n",
    "\n",
    "    pairwise_data = vstack(pairwise_data)\n",
    "    \n",
    "    return pairwise_data, pairwise_class\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "train, test = load_amazon_reviews_no_dups(amazon_review_dir + \"reviews_Musical_Instruments_5.json.gz\",test_size=200) \n",
    "train_features,train_scores, test_features,test_scores = prepare_for_regression(train,test)\n",
    "pairwise_data, pairwise_class = convert_to_pairwise(train_features,train_scores)\n",
    "assert pairwise_data.shape == train_features.shape\n",
    "assert len(set(pairwise_class)) == 2\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "rubric={accuracy:2}\n",
    "\n",
    "Use `convert to pairwise` to carry out SVM ranking. Note that although you are converting the training set to pairwise, you don't do this for the test set. Note also that you can't use the `predict` function for the resulting classifier because the result would be a class. Instead, you want the result from taking a dot product of each feature vector and the weights of the SVM classifier (`coef_`). Again, evaluate the performance in the 3 corpora using Kendall's tau. You should get strikingly better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5931139675123936\n"
     ]
    }
   ],
   "source": [
    "prediction = list()\n",
    "for feature in X_test:\n",
    "    dot_product = np.sum(feature.multiply(clf.coef_))\n",
    "    #print(dot_product)\n",
    "\n",
    "    prediction.append(dot_product)\n",
    "tau, p_value = kendalltau(test_class, prediction)\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beauty': (0.5646617167809718, 2.713317398151985e-239),\n",
       " 'cell_phone': (0.5493441588182651, 2.6247682759398534e-229),\n",
       " 'video': (0.5170716574294437, 3.884122453122774e-204)}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set should use the 2000\n",
    "result = dict()\n",
    "for i in range(len(all_train)):\n",
    "    prediction = list()\n",
    "    X_train, train_class, X_test, test_class = prepare_for_regression(all_train[i], all_test[i], best_n_gram[i])\n",
    "    pairwise_data, pairwise_class = convert_to_pairwise(X_train,train_class)\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(pairwise_data, pairwise_class)\n",
    "    for feature in X_test:\n",
    "        dot_product = np.sum(feature.multiply(clf.coef_))\n",
    "        #print(dot_product)\n",
    "\n",
    "        prediction.append(dot_product)\n",
    "    tau, p_value = kendalltau(test_class, prediction)\n",
    "    result[data[i]] = (tau, p_value)\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Pollyannas and Negative Nellies\n",
    "rubric={accuracy:3,quality:1}\n",
    "\n",
    "In this exercise, we are going to see how well our automated system is able to duplicate the conclusions of a simple kind of \"author profiling\" based on gold standard ratings. Two functions are provided to you: the first is `load_amazon_reviews_reviewer_groups` (a variation on `load_amazon_reviews_no_dups`) which creates a test set consisting of reviews written by authors with a total of at least 20 reviews; the training set consists of all other reviews.\n",
    "\n",
    "The second function uses the test set to derive a list of \"Pollyannas\" and \"Negative Nellies\". The former is defined as reviewers who have only given five star reviews, and the latter are those reviewers whose average review rating is below 3 (True Negative Nellies, those who only give 1 star reviews, do not seem to exist! The Pollyanna hypothesis at work yet again...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_min = 20\n",
    "\n",
    "def load_amazon_reviews_reviewer_groups(corpus_path,test_size=2000,seed=42):\n",
    "    '''loads a gzipped amazon review corpus, prepare a test set consisting of reviews whose reviewers\n",
    "    have at least 20 total reviews, and the training set consisting of all other reviews'''\n",
    "    g = gzip.open(corpus_path, 'r')\n",
    "    all_reviews = [eval(line) for line in g]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(all_reviews)\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    reviewer_groups = defaultdict(list)\n",
    "    for i,review in enumerate(all_reviews):\n",
    "        reviewer_groups[review[\"reviewerID\"]].append(review)\n",
    "    for reviewer_group in reviewer_groups.values():\n",
    "        if len(reviewer_group) > review_min:\n",
    "            for review in reviewer_group:\n",
    "                test_set.append(review)\n",
    "        else:\n",
    "            train_set.extend(reviewer_group)\n",
    "        \n",
    "    return train_set,test_set\n",
    "\n",
    "\n",
    "def get_pollyannas_and_nellies(reviews):\n",
    "    '''get a list of pollyannas (reviewers with only 5 star reviews) and negative nellies (those\n",
    "    whose average rating is negative) based on the list of reviews'''\n",
    "    reviewer_ratings = defaultdict(list)\n",
    "    nellies = set()\n",
    "    pollyannas = set()\n",
    "    for review in reviews:\n",
    "        reviewer_ratings[review[\"reviewerID\"]].append(review[\"overall\"])\n",
    "    for reviewer,ratings in reviewer_ratings.items():\n",
    "        avg = sum(ratings)/len(ratings)\n",
    "        if avg < 3:\n",
    "            nellies.add(reviewer)\n",
    "        if avg == 5:\n",
    "            pollyannas.add(reviewer)\n",
    "    return pollyannas,nellies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SVM ranking approach from exercise 2 to derived automatic ratings to the reviews for all reviewers with at least 20 reviews (i.e. the test set provided by `load_amazon_reviews_reviewer_groups`). Then use these ratings to rank the reviewers by the average positivity of their reviews, and see what percentage of the gold standard \"Nellies\" (as identified by `get_pollyannas_and_nellies`) are in the bottom 20% in terms of (automatically-determined) average positivity, and what percentage of gold standard \"Pollyannas\" are in the top 20%. A high score indicates that we are more or less able to re-identify reviewers with strongly positive and negative biases using only automatically-generated review scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty_train, beauty_test = load_amazon_reviews_reviewer_groups(amazon_review_dir + \"reviews_Beauty_5.json.gz\")\n",
    "cell_phone_train, cell_phone_test = load_amazon_reviews_reviewer_groups(amazon_review_dir + \"reviews_Cell_Phones_and_Accessories_5.json.gz\")\n",
    "video_train, video_test = load_amazon_reviews_reviewer_groups(amazon_review_dir + \"reviews_Video_Games_5.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_group_train = [beauty_train, cell_phone_train, video_train]\n",
    "review_group_test = [beauty_test, cell_phone_test, video_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beauty  Polyanna accuracy:  0.8813559322033898\n",
      "**************\n",
      "beauty  Nellies accuracy:  0.95\n",
      "**************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_phone  Polyanna accuracy:  0.5714285714285714\n",
      "**************\n",
      "cell_phone  Nellies accuracy:  1.0\n",
      "**************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chidera/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video  Polyanna accuracy:  0.625\n",
      "**************\n",
      "video  Nellies accuracy:  0.8596491228070176\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "all_data = list()\n",
    "for i in range(len(review_group_train)):\n",
    "    review_rank = defaultdict(list)\n",
    "    prediction = list()\n",
    "    sorted_rev = dict()\n",
    "    X_train, train_class, X_test, test_class = prepare_for_regression(review_group_train[i], review_group_test[i], best_n_gram[i])\n",
    "    pairwise_data, pairwise_class = convert_to_pairwise(X_train,train_class)\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(pairwise_data, pairwise_class)\n",
    "    for j in range(len(test_class)):\n",
    "        dot_product = np.sum(X_test[j].multiply(clf.coef_))\n",
    "        review_rank[review_group_test[i][j]['reviewerID']].append(dot_product)\n",
    "    \n",
    "    \n",
    "    ## Sorting the reviews \n",
    "    for review in review_rank:\n",
    "        sorted_rev[review] = sum(review_rank[review])/len(review_rank[review])\n",
    "    sort_review = sorted(sorted_rev, key=sorted_rev.get)\n",
    "    ratio = len(sort_review) * 0.2\n",
    "    pred_polyannas = sort_review[-int(ratio):]\n",
    "    pred_nellies = sort_review[:int(ratio)]\n",
    "    \n",
    "    ### Evaluation for polyannas \n",
    "    correct = 0\n",
    "    gold_polyannas, gold_nellies = get_pollyannas_and_nellies(review_group_test[i])\n",
    "    for poly in pred_polyannas:\n",
    "        if poly in gold_polyannas:\n",
    "            correct += 1\n",
    "    poly_accuracy = correct/len(gold_polyannas)\n",
    "    print(data[i], \" Polyanna accuracy: \", poly_accuracy)\n",
    "    print('**************')\n",
    "    \n",
    "    ### Evaluation for nellies \n",
    "    correct = 0\n",
    "\n",
    "    for nellie in pred_nellies:\n",
    "        if nellie in gold_nellies:\n",
    "            correct += 1\n",
    "    nellie_accuracy = correct/len(gold_nellies)\n",
    "    print(data[i], \" Nellies accuracy: \", nellie_accuracy)\n",
    "    \n",
    "    print('**************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Sarcasm hunt (Optional)\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Use some automatic method to find sarcasm in the Amazon Review corpus. You can use any method EXCEPT looking for explicit mentions of the word sarcasm (or related words). It's okay if you have to do some manual checking, but your automatic approach should greatly narrow it down. You can get most of the points in this problem if you find at least one, but for full points you should find more, at least 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
